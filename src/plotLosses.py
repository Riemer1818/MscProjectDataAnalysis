import json
import pandas as pd

# Function to combine loss data
def combine_losses(loss_dicts, names):
    combined_data = {'Epoch': list(range(1, len(loss_dicts[0]["train_losses"]) + 1))}
    
    for i, loss_dict in enumerate(loss_dicts):
        name = names[i]
        combined_data[f'{name}_train_losses'] = loss_dict['train_losses']
        combined_data[f'{name}_val_losses'] = loss_dict['val_losses']
    
    # Convert to DataFrame for better visualization
    df = pd.DataFrame(combined_data)
    return df

# batch_size = 16
# INTERACTION_DATA_FILE = '9606.protein.physical.links.v12.0.txt.gz'
# HDF5_GRAPH_FILE = "protein.physical.links.full_links.h5"
# num_layers = 1
# hidden_channels = 1
# num_epochs = 15
# learning_rate = 0.001
# checkpoint_dir = 'checkpoints_diffModels'
# T_max = 10
# in_channels = 1

# Example usage:
GCN = {"train_losses": [1.2853934712707997, 1.1427199734995763, 1.0769795949260395, 1.0573438628887137, 1.0529261578495304, 1.0498781709000469, 1.0496377904588978, 1.0491315812493365, 1.0480997083708643, 1.0487863240142663, 1.0479579812536637, 1.0479158245027065, 1.0478842345997692, 1.0469282674292724, 1.0475962419062852], "val_losses": [1.1784403691689174, 1.0776530355215073, 1.0440592293938, 1.033993053684632, 1.0305967681109904, 1.029221628854672, 1.0285829226175944, 1.0282608039677144, 1.0281217937668166, 1.0280890122056008, 1.028089019904534, 1.0280538241068522, 1.0279215313494205, 1.0276922608415286, 1.0273095207909744]}

GAT = {"train_losses": [1.2351417382558187, 1.1083658937364818, 1.0426680377374093, 1.013854324258864, 0.9965771298855544, 0.9897453540315231, 0.986462255505224, 0.9882730095957716, 0.9850134432936708, 0.9855397303899129, 0.9862804874156912, 0.9854533727591236, 0.984392301676174, 0.984662922595938, 0.9855369140704473], "val_losses": [1.1875095640619595, 1.097330098847548, 1.0530982037385306, 1.0321306578814984, 1.0224951356649399, 1.017947102834781, 1.0157999150454997, 1.01480384071668, 1.0143944434821606, 1.0142887338995934, 1.0142887338995934, 1.014175688723723, 1.0137750118970872, 1.0130496678253016, 1.012265107035637]}

GIN = {"train_losses": [1.2741757236421107, 1.1147107613583407, 1.0386162299041948, 1.005586242241164, 0.9912151970590154, 0.986315282372137, 0.9849942407260338, 0.9838755392159025, 0.9824798836062352, 0.9815166881928842, 0.9822477464253704, 0.9812959283590317, 0.982268662750721, 0.9810862847914298, 0.9821930802116792], "val_losses": [1.2016097232699394, 1.1014881417155267, 1.046771366894245, 1.0264209633072217, 1.0180475088457266, 1.0146213814616203, 1.0130934303005537, 1.0124486428995927, 1.0122049334148566, 1.0121324102083842, 1.012396151572466, 1.0121585331857204, 1.0120248104135194, 1.0114329566558202, 1.0111017152667046]}

GATWithBatchNorm = {"train_losses": [1.2590775431444248, 1.1247625559568406, 1.0604218313470484, 1.034955526019136, 1.0244718790675202, 1.0213202545419335, 1.0213784278059999, 1.018959212116897, 1.0197825407609344, 1.0185815887525678, 1.0185765262693167, 1.0193583487843474, 1.020093326891462, 1.0190753520776827, 1.0173377667864163], "val_losses": [1.173350447913011, 1.0818191841244698, 1.0422927061716716, 1.0269506509105364, 1.0212339093287786, 1.0190926946699619, 1.0182066542406878, 1.0179914434750874, 1.0179193568726381, 1.0177433140575887, 1.0178439589838186, 1.01768597488602, 1.017485824227333, 1.0171051348249118, 1.01684979647398]}

GATWithDropout = {"train_losses": [1.2421390682458877, 1.1174467181166012, 1.0491469296316305, 1.0279766947031022, 1.0199519954621792, 1.0184372633695602, 1.014654200958709, 1.0148640173176924, 1.0137723443408808, 1.0145534613480172, 1.0186721269662182, 1.0152912998571992, 1.0143721108014385, 1.0133409776414435, 1.0129059641932447], "val_losses": [1.3044004042943318, 1.2883026947577794, 1.21657352099816, 1.1658697873353958, 1.1438669179876646, 1.1371611922979354, 1.1290626471241316, 1.126601722339789, 1.1253969962398211, 1.1251935839653016, 1.1251935611168544, 1.1249214400847753, 1.1241740629076957, 1.1223137458165486, 1.1204123049974442]}

# Combine the losses from different files
combined_df = combine_losses([GCN, GAT, GIN, GATWithBatchNorm, GATWithDropout], ["GCN", "GAT", "GIN", "GCNWithBatchNorm", "GATWithDropout"])

# Save or display the combined data
combined_df.to_csv("combined_losses.csv", index=False)
print(combined_df)

import matplotlib.pyplot as plt

# Plot the training losses
plt.figure(figsize=(10, 6))

for col in combined_df.columns:
    if 'train_losses' in col:
        plt.plot(combined_df['Epoch'], combined_df[col], label=col)

plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Losses')
plt.legend()
plt.grid(True)
plt.savefig("combined_train_losses_plot.png")
plt.show()

# Plot the validation losses
plt.figure(figsize=(10, 6))

for col in combined_df.columns:
    if 'val_losses' in col:
        plt.plot(combined_df['Epoch'], combined_df[col], label=col)

plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Validation Losses')
plt.legend()
plt.grid(True)
plt.savefig("combined_val_losses_plot.png")
plt.show()